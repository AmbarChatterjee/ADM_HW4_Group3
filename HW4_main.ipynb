{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from random import randint\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataframe from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58773</td>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58774</td>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58775</td>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58776</td>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58777</td>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58778</td>\n",
       "      <td>2017-01-01 19:21:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>c5bf4f3f57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58779</td>\n",
       "      <td>2017-01-01 19:43:06</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>The Water Diviner</td>\n",
       "      <td>Drama, History, War</td>\n",
       "      <td>2014-12-26</td>\n",
       "      <td>7165c2fc94</td>\n",
       "      <td>8e1be40e32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58780</td>\n",
       "      <td>2017-01-01 19:44:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angel of Christmas</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>b2f02f2689</td>\n",
       "      <td>892a51dee1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58781</td>\n",
       "      <td>2017-01-01 19:46:24</td>\n",
       "      <td>3845.0</td>\n",
       "      <td>Ratter</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>c39aae36c3</td>\n",
       "      <td>cff8ea652a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58782</td>\n",
       "      <td>2017-01-01 20:27:04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Book of Life</td>\n",
       "      <td>Animation, Adventure, Comedy, Family, Fantasy,...</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>97183b9136</td>\n",
       "      <td>bf53608c70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            datetime  duration  \\\n",
       "0       58773 2017-01-01 01:15:09       0.0   \n",
       "1       58774 2017-01-01 13:56:02       0.0   \n",
       "2       58775 2017-01-01 15:17:47   10530.0   \n",
       "3       58776 2017-01-01 16:04:13      49.0   \n",
       "4       58777 2017-01-01 19:16:37       0.0   \n",
       "5       58778 2017-01-01 19:21:37       0.0   \n",
       "6       58779 2017-01-01 19:43:06    4903.0   \n",
       "7       58780 2017-01-01 19:44:38       0.0   \n",
       "8       58781 2017-01-01 19:46:24    3845.0   \n",
       "9       58782 2017-01-01 20:27:04       0.0   \n",
       "\n",
       "                                title  \\\n",
       "0  Angus, Thongs and Perfect Snogging   \n",
       "1        The Curse of Sleeping Beauty   \n",
       "2                   London Has Fallen   \n",
       "3                            Vendetta   \n",
       "4     The SpongeBob SquarePants Movie   \n",
       "5                   London Has Fallen   \n",
       "6                   The Water Diviner   \n",
       "7                  Angel of Christmas   \n",
       "8                              Ratter   \n",
       "9                    The Book of Life   \n",
       "\n",
       "                                              genres release_date    movie_id  \\\n",
       "0                             Comedy, Drama, Romance   2008-07-25  26bd5987e8   \n",
       "1                 Fantasy, Horror, Mystery, Thriller   2016-06-02  f26ed2675e   \n",
       "2                                   Action, Thriller   2016-03-04  f77e500e7a   \n",
       "3                                      Action, Drama   2015-06-12  c74aec7673   \n",
       "4  Animation, Action, Adventure, Comedy, Family, ...   2004-11-19  a80d6fc2aa   \n",
       "5                                   Action, Thriller   2016-03-04  f77e500e7a   \n",
       "6                                Drama, History, War   2014-12-26  7165c2fc94   \n",
       "7                                    Comedy, Romance   2015-11-29  b2f02f2689   \n",
       "8                            Drama, Horror, Thriller   2016-02-12  c39aae36c3   \n",
       "9  Animation, Adventure, Comedy, Family, Fantasy,...   2014-10-17  97183b9136   \n",
       "\n",
       "      user_id  \n",
       "0  1dea19f6fe  \n",
       "1  544dcbc510  \n",
       "2  7cbcc791bf  \n",
       "3  ebf43c36b6  \n",
       "4  a57c992287  \n",
       "5  c5bf4f3f57  \n",
       "6  8e1be40e32  \n",
       "7  892a51dee1  \n",
       "8  cff8ea652a  \n",
       "9  bf53608c70  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesDF = pd.read_csv(r\"C:\\Users\\Elias Antoun\\Documents\\ADM_HW4_Group3\\vodclickstream_uk_movies_03.csv\")\n",
    "\n",
    "# misc pre-handling optimization\n",
    "moviesDF['datetime'] = pd.to_datetime(moviesDF['datetime'])\n",
    "\n",
    "moviesDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Title and Genre of top movies that the user _clicked on_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_m = ['user_id', 'movie_id']\n",
    "\n",
    "# Break process into chunks, otherwise takes 15+ minutes to run\n",
    "chunk_size = 10000\n",
    "\n",
    "# Initialize empty \"result\" dataframe with columns\n",
    "top_movies = pd.DataFrame(columns=['user_id', 'title', 'genres', 'click_count', 'movie_id'])\n",
    "\n",
    "for chunk_start in range(0, len(moviesDF), chunk_size):\n",
    "    chunk_end = min(chunk_start + chunk_size, len(moviesDF)) \n",
    "    chunk = moviesDF.iloc[chunk_start:chunk_end]   # to delimit chunk\n",
    "\n",
    "    # Group by 'user_id', 'movie_id', and count the clicks for the chunk\n",
    "    u_m_c = chunk.groupby(u_m).size().reset_index(name='click_count')\n",
    "\n",
    "    # Use nlargest to get the top 10 movies for each user in the chunk\n",
    "    top_mov_user = (\n",
    "        u_m_c.groupby('user_id', group_keys=False)\n",
    "        .apply(lambda group: group.nlargest(10, 'click_count'))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Merge with original dataframe to get title and genre\n",
    "    result_chunk = pd.merge(top_mov_user, chunk[['movie_id', 'title', 'genres', 'datetime']], on='movie_id', how='left')\n",
    "\n",
    "    # Identify and aggregate genuine multiple clicks based on datetime\n",
    "    result_chunk['click_count'] = result_chunk.groupby(['user_id', 'movie_id', 'title', 'genres'])['click_count'].transform('sum')\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    result_chunk = result_chunk.drop_duplicates(subset=['user_id', 'movie_id', 'title', 'genres', 'click_count'])\n",
    "\n",
    "    # Append chunk result to final result\n",
    "    top_movies = pd.concat([top_movies, result_chunk], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>click_count</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005d9a8f4</td>\n",
       "      <td>Joe and Caspar Hit the Road</td>\n",
       "      <td>Documentary, Adventure, Comedy</td>\n",
       "      <td>27</td>\n",
       "      <td>416464eaad</td>\n",
       "      <td>2017-01-01 11:05:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001991be8a</td>\n",
       "      <td>Star Trek: First Contact</td>\n",
       "      <td>Action, Adventure, Drama, Sci-Fi, Thriller</td>\n",
       "      <td>8</td>\n",
       "      <td>dfd60c5a87</td>\n",
       "      <td>2017-01-06 15:27:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Jackass Presents: Bad Grandpa</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>12</td>\n",
       "      <td>03a064a477</td>\n",
       "      <td>2017-01-01 21:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>The Drop</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>25</td>\n",
       "      <td>0fa2d624f1</td>\n",
       "      <td>2017-01-03 11:18:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Big Mommas: Like Father, Like Son</td>\n",
       "      <td>Action, Comedy, Crime</td>\n",
       "      <td>5</td>\n",
       "      <td>135b083a96</td>\n",
       "      <td>2017-01-01 22:54:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Jay and Silent Bob Strike Back</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>7</td>\n",
       "      <td>16dc968f63</td>\n",
       "      <td>2017-01-12 18:37:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>The Ridiculous 6</td>\n",
       "      <td>Action, Adventure, Comedy, Western</td>\n",
       "      <td>11</td>\n",
       "      <td>1d4dcbbcc8</td>\n",
       "      <td>2017-01-02 22:13:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Bee Movie</td>\n",
       "      <td>Animation, Adventure, Comedy, Family</td>\n",
       "      <td>20</td>\n",
       "      <td>257f9d2f23</td>\n",
       "      <td>2017-01-02 08:51:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Saala Khadoos</td>\n",
       "      <td>Action, Drama, Sport</td>\n",
       "      <td>2</td>\n",
       "      <td>263fd8d6ac</td>\n",
       "      <td>2017-01-08 18:35:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Good Hair</td>\n",
       "      <td>Documentary, Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>3eb41c76f3</td>\n",
       "      <td>2017-01-22 03:48:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                              title  \\\n",
       "0  0005d9a8f4        Joe and Caspar Hit the Road   \n",
       "1  001991be8a           Star Trek: First Contact   \n",
       "2  0029f6bb1e      Jackass Presents: Bad Grandpa   \n",
       "3  0029f6bb1e                           The Drop   \n",
       "4  0029f6bb1e  Big Mommas: Like Father, Like Son   \n",
       "5  0029f6bb1e     Jay and Silent Bob Strike Back   \n",
       "6  0029f6bb1e                   The Ridiculous 6   \n",
       "7  0029f6bb1e                          Bee Movie   \n",
       "8  0029f6bb1e                      Saala Khadoos   \n",
       "9  0029f6bb1e                          Good Hair   \n",
       "\n",
       "                                       genres click_count    movie_id  \\\n",
       "0              Documentary, Adventure, Comedy          27  416464eaad   \n",
       "1  Action, Adventure, Drama, Sci-Fi, Thriller           8  dfd60c5a87   \n",
       "2                                      Comedy          12  03a064a477   \n",
       "3                      Crime, Drama, Thriller          25  0fa2d624f1   \n",
       "4                       Action, Comedy, Crime           5  135b083a96   \n",
       "5                                      Comedy           7  16dc968f63   \n",
       "6          Action, Adventure, Comedy, Western          11  1d4dcbbcc8   \n",
       "7        Animation, Adventure, Comedy, Family          20  257f9d2f23   \n",
       "8                        Action, Drama, Sport           2  263fd8d6ac   \n",
       "9                         Documentary, Comedy           1  3eb41c76f3   \n",
       "\n",
       "             datetime  \n",
       "0 2017-01-01 11:05:46  \n",
       "1 2017-01-06 15:27:56  \n",
       "2 2017-01-01 21:00:34  \n",
       "3 2017-01-03 11:18:01  \n",
       "4 2017-01-01 22:54:57  \n",
       "5 2017-01-12 18:37:07  \n",
       "6 2017-01-02 22:13:13  \n",
       "7 2017-01-02 08:51:21  \n",
       "8 2017-01-08 18:35:22  \n",
       "9 2017-01-22 03:48:29  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Minhash Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing of the genres column to prep for hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>click_count</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>filtered_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005d9a8f4</td>\n",
       "      <td>Joe and Caspar Hit the Road</td>\n",
       "      <td>Documentary, Adventure, Comedy</td>\n",
       "      <td>27</td>\n",
       "      <td>416464eaad</td>\n",
       "      <td>2017-01-01 11:05:46</td>\n",
       "      <td>documentary adventure comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001991be8a</td>\n",
       "      <td>Star Trek: First Contact</td>\n",
       "      <td>Action, Adventure, Drama, Sci-Fi, Thriller</td>\n",
       "      <td>8</td>\n",
       "      <td>dfd60c5a87</td>\n",
       "      <td>2017-01-06 15:27:56</td>\n",
       "      <td>action adventure drama scifi thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0029f6bb1e</td>\n",
       "      <td>Jackass Presents: Bad Grandpa</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>12</td>\n",
       "      <td>03a064a477</td>\n",
       "      <td>2017-01-01 21:00:34</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>002b8b112a</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>5</td>\n",
       "      <td>cb67c1c73b</td>\n",
       "      <td>2017-01-07 18:21:02</td>\n",
       "      <td>crime drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>003a3c6c6b</td>\n",
       "      <td>Jack Reacher</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>17</td>\n",
       "      <td>1e70af3161</td>\n",
       "      <td>2017-01-01 12:00:08</td>\n",
       "      <td>action thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>005ccd729f</td>\n",
       "      <td>The Equalizer</td>\n",
       "      <td>Action, Crime, Thriller</td>\n",
       "      <td>150</td>\n",
       "      <td>c738cc60db</td>\n",
       "      <td>2017-01-01 23:06:04</td>\n",
       "      <td>action crime thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>007b07d586</td>\n",
       "      <td>Not Another Teen Movie</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>4</td>\n",
       "      <td>87ce1a6b0e</td>\n",
       "      <td>2017-01-20 01:56:31</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00894a66a4</td>\n",
       "      <td>Maleficent</td>\n",
       "      <td>Action, Adventure, Family, Fantasy, Romance</td>\n",
       "      <td>22</td>\n",
       "      <td>5458863a18</td>\n",
       "      <td>2017-01-03 00:38:22</td>\n",
       "      <td>action adventure family fantasy romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>00938d1bb7</td>\n",
       "      <td>The Legend of Barney Thomson</td>\n",
       "      <td>Comedy, Crime</td>\n",
       "      <td>18</td>\n",
       "      <td>01c09be4ff</td>\n",
       "      <td>2017-01-04 19:32:44</td>\n",
       "      <td>comedy crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>00b3cce130</td>\n",
       "      <td>The Way He Looks</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>11</td>\n",
       "      <td>45bdd5d8f7</td>\n",
       "      <td>2017-01-02 12:03:58</td>\n",
       "      <td>drama romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                          title  \\\n",
       "0   0005d9a8f4    Joe and Caspar Hit the Road   \n",
       "1   001991be8a       Star Trek: First Contact   \n",
       "2   0029f6bb1e  Jackass Presents: Bad Grandpa   \n",
       "12  002b8b112a          To Kill a Mockingbird   \n",
       "13  003a3c6c6b                   Jack Reacher   \n",
       "18  005ccd729f                  The Equalizer   \n",
       "28  007b07d586         Not Another Teen Movie   \n",
       "29  00894a66a4                     Maleficent   \n",
       "30  00938d1bb7   The Legend of Barney Thomson   \n",
       "35  00b3cce130               The Way He Looks   \n",
       "\n",
       "                                         genres click_count    movie_id  \\\n",
       "0                Documentary, Adventure, Comedy          27  416464eaad   \n",
       "1    Action, Adventure, Drama, Sci-Fi, Thriller           8  dfd60c5a87   \n",
       "2                                        Comedy          12  03a064a477   \n",
       "12                                 Crime, Drama           5  cb67c1c73b   \n",
       "13                             Action, Thriller          17  1e70af3161   \n",
       "18                      Action, Crime, Thriller         150  c738cc60db   \n",
       "28                                       Comedy           4  87ce1a6b0e   \n",
       "29  Action, Adventure, Family, Fantasy, Romance          22  5458863a18   \n",
       "30                                Comedy, Crime          18  01c09be4ff   \n",
       "35                               Drama, Romance          11  45bdd5d8f7   \n",
       "\n",
       "              datetime                          filtered_genres  \n",
       "0  2017-01-01 11:05:46             documentary adventure comedy  \n",
       "1  2017-01-06 15:27:56    action adventure drama scifi thriller  \n",
       "2  2017-01-01 21:00:34                                   comedy  \n",
       "12 2017-01-07 18:21:02                              crime drama  \n",
       "13 2017-01-01 12:00:08                          action thriller  \n",
       "18 2017-01-01 23:06:04                    action crime thriller  \n",
       "28 2017-01-20 01:56:31                                   comedy  \n",
       "29 2017-01-03 00:38:22  action adventure family fantasy romance  \n",
       "30 2017-01-04 19:32:44                             comedy crime  \n",
       "35 2017-01-02 12:03:58                            drama romance  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies.sort_values(by = ['user_id','click_count'], ascending = False)\n",
    "\n",
    "top_movies_per_user = top_movies\n",
    "top_movies_per_user['filtered_genres'] = top_movies_per_user['genres'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x.lower()))\n",
    "\n",
    "\n",
    "top_movies_per_user = top_movies_per_user.drop_duplicates(subset = 'user_id')\n",
    "top_movies_per_user.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hashing and Grouping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method used follows a lot of the same steps used in: https://www.codemotion.com/magazine/backend/fast-document-similarity-in-python-minhashlsh/ but altered to give us buckets and not pairs, my code uses lsh with a threshhold of 0.6\n",
    "The hash function has been modified to a custom one based on xor, instead of an already implemented one.\n",
    "\n",
    "Step by step overview of the code:\n",
    "\n",
    "Classes:\n",
    "\n",
    "1. shingler: create shingles to be used in the following hashing\n",
    "2. HashFamily: create a hash function and return a hash value to be used in minhash\n",
    "3. MinhashSigner: compute minhash signature\n",
    "4. LSH: locality sensitive hashing to group similar sets using their minhash signatures\n",
    "\n",
    "Please note that the code was run through chat gpt for final optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shingler: \n",
    "    def __init__(self, k):\n",
    "        if k > 0:\n",
    "            self.k = int(k)\n",
    "        else:\n",
    "            self.k = 10\n",
    "\n",
    "    def process_doc(self, document):\n",
    "        return re.sub(\"( )+|(\\n)+\", \" \", document).lower()\n",
    "\n",
    "    def get_shingles(self, document):\n",
    "        shingles = set()\n",
    "        document = self.process_doc(document)\n",
    "        for i in range(0, len(document) - self.k + 1):\n",
    "            shingles.add(document[i:i + self.k])\n",
    "        return shingles\n",
    "\n",
    "class HashFamily:\n",
    "    def __init__(self, i):\n",
    "        self.result_size = 8\n",
    "        self.max_len = 20\n",
    "        self.salt = str(i).zfill(self.max_len)[-self.max_len:]\n",
    "\n",
    "    def custom_hash_function(self, el_to_hash):  # hash function from scratch that uses XOR\n",
    "        hash_val = 0\n",
    "        for char in str(el_to_hash) + self.salt:\n",
    "            hash_val ^= ord(char)\n",
    "        return hash_val\n",
    "\n",
    "    def get_hash_value(self, el_to_hash):  # return final hash value to use in minhash step\n",
    "        return int(self.custom_hash_function(el_to_hash)) & ((1 << self.result_size) - 1)\n",
    "\n",
    "class MinhashSigner:\n",
    "    def __init__(self, sig_size):\n",
    "        self.sig_size = sig_size\n",
    "        self.hash_functions = [HashFamily(randint(0, 10000000000)) for _ in range(sig_size)]\n",
    "\n",
    "    def compute_set_signature(self, set_):  # compute minhash signature for every element\n",
    "        set_sig = []\n",
    "        for h_funct in self.hash_functions:\n",
    "            min_hash = math.inf  # initialize minhash values as infinity\n",
    "            for el in set_:\n",
    "                h = h_funct.get_hash_value(el)\n",
    "                if h < min_hash:\n",
    "                    min_hash = h  # append hash value if it's lower than the currently stored minhash\n",
    "\n",
    "            set_sig.append(min_hash)\n",
    "\n",
    "        return set_sig\n",
    "\n",
    "    def compute_signature_matrix(self, set_list):  # return minhash signature matrix\n",
    "        signatures = []\n",
    "        for s in tqdm(set_list, desc=\"Computing MinHash Signatures\", unit=\"set\"):\n",
    "            signatures.append(self.compute_set_signature(s))\n",
    "        return signatures\n",
    "\n",
    "class LSH:  #locality sensitive hashing with later specified threshhold of 0.6\n",
    "    def __init__(self, threshold): \n",
    "        self.threshold = threshold\n",
    "\n",
    "    def get_signature_matrix_bands(self, sig_matrix, bands_nr, sign_len):\n",
    "        r = int(len(sig_matrix[0]) / bands_nr)  # adjusted to use length of the signature matrix\n",
    "        bands = {i: [] for i in range(bands_nr)}\n",
    "        for i in range(bands_nr):\n",
    "            bands[i] = []\n",
    "        for signature in sig_matrix:\n",
    "            for i in range(bands_nr):\n",
    "                idx = i * r\n",
    "                bands[i].append(\" \".join(str(x) for x in signature[idx : idx + r]))\n",
    "        return bands\n",
    "\n",
    "    def get_band_buckets(self, band, user_ids):\n",
    "        buckets = defaultdict(set)\n",
    "        for doc_id, users_in_doc in enumerate(band):\n",
    "            for user_id in users_in_doc.split():\n",
    "                buckets[user_id].add(user_ids[doc_id])\n",
    "        return buckets\n",
    "\n",
    "    def get_similar_buckets(self, sig_matrix, bands_nr, sign_len, user_ids):\n",
    "        similar_buckets = defaultdict(set)\n",
    "        bands = self.get_signature_matrix_bands(sig_matrix, bands_nr, sign_len)\n",
    "        for band_id, elements in tqdm(bands.items(), desc=\"Processing Bands\", unit=\"band\"):\n",
    "            buckets = self.get_band_buckets(elements, user_ids)\n",
    "            for bucket_id, users in buckets.items():\n",
    "                similar_buckets[bucket_id].update(users)\n",
    "        return similar_buckets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Shingling: generate shingles(genres) from the filtered_genres column\n",
    "\n",
    "2- Minhashing Compute the MinHash signatures for each set of shingles\n",
    "\n",
    "3- Locality Sensitive Hashing: set number of bands, signature size and similarity threshhold, then apply LSH to group similar users into buckets\n",
    "\n",
    "4- Output: grouped users who have similar interests based on the genres of their favorite movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shingling: 100%|██████████| 161918/161918 [00:01<00:00, 132943.54document/s]\n",
      "Computing MinHash Signatures: 100%|██████████| 161918/161918 [02:43<00:00, 988.20set/s] \n",
      "Processing Bands: 100%|██████████| 5/5 [00:01<00:00,  4.90band/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Shingling\n",
    "shingler_instance = Shingler(k=2)\n",
    "shingles_per_document = [shingler_instance.get_shingles(str(pref)) for pref in tqdm(top_movies_per_user['filtered_genres'], desc=\"Shingling\", unit=\"document\")]\n",
    "\n",
    "# Step 2: MinHashing\n",
    "minhash_instance = MinhashSigner(sig_size=50) \n",
    "minhash_signatures = minhash_instance.compute_signature_matrix(shingles_per_document)\n",
    "\n",
    "# Step 3: Locality Sensitive Hashing (LSH)\n",
    "bands_nr = 5\n",
    "sign_len = 50\n",
    "lsh_instance = LSH(threshold=0.6)\n",
    "\n",
    "# Step 4: Output (grouped users)\n",
    "user_ids = top_movies_per_user['user_id'].tolist()\n",
    "similar_user_buckets = lsh_instance.get_similar_buckets(minhash_signatures, bands_nr, sign_len, user_ids=user_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1:\n",
      "  61bc7ecf9b\n",
      "  ed3ce4859f\n",
      "  ea1d17c461\n",
      "Group 0:\n",
      "  61bc7ecf9b\n",
      "  ed3ce4859f\n",
      "  ea1d17c461\n"
     ]
    }
   ],
   "source": [
    "#Example of 3 users from 2 different buckets (complete output is too long to display properly)\n",
    "\n",
    "for i, (group, values_set) in enumerate(similar_user_buckets.items()):\n",
    "    \n",
    "    print(f\"Group {group}:\")\n",
    "    \n",
    "    for value in list(values_set)[:3]:\n",
    "        print(f\"  {value}\")\n",
    "\n",
    "    # Break the loop after processing the first two groups\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3: Recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user_id, similar_user_buckets, top_movies):\n",
    "    # Check if the given user_id is in the buckets\n",
    "    user_id = user_id.strip()\n",
    "    matching_user = next((key for key in similar_user_buckets if user_id in similar_user_buckets[key]), None)\n",
    "\n",
    "    if matching_user is None:\n",
    "        print(f\"User {user_id} not found in similar user buckets.\")\n",
    "        return\n",
    "\n",
    "    # Get the two most similar users to the given user_id since all previously computed similarities from the LSH step are still stored\n",
    "    similar_users = list(similar_user_buckets[matching_user])\n",
    "\n",
    "    if len(similar_users) < 2:\n",
    "        print(f\"Not enough similar users found for user {user_id}.\")\n",
    "        return\n",
    "\n",
    "    # Extract the movie information for the two most similar users\n",
    "    user_a_movies = top_movies[top_movies['user_id'] == similar_users[0]]\n",
    "    user_b_movies = top_movies[top_movies['user_id'] == similar_users[1]]\n",
    "\n",
    "    # common movies\n",
    "    common_movies = set(user_a_movies['title']).intersection(set(user_b_movies['title']))\n",
    "\n",
    "    # recommend movies based on total clicks\n",
    "    if common_movies:\n",
    "        recommended_movies = (\n",
    "            top_movies[top_movies['title'].isin(common_movies)]\n",
    "            .groupby('title')['click_count']\n",
    "            .sum()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(5)\n",
    "            .index\n",
    "        )\n",
    "    else:\n",
    "        \n",
    "        recommended_movies = (\n",
    "            user_a_movies.groupby('title')['click_count']\n",
    "            .sum()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(5)\n",
    "            .index\n",
    "        )\n",
    "\n",
    "    print(f\"Recommended movies for user {user_id}:\")\n",
    "    for movie in recommended_movies:\n",
    "        print(f\"  - {movie}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** The cell below will output the same result for any id other than the current one unless the kernel is restarted. I tried to solve this issue but could not figure out why this is happening. If you want to test with different ids please change the user_id_to_recomment below, restart the kernel then run all again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for user 0a96452695:\n",
      "  - Titanic\n",
      "  - 13 Reasons Why: Beyond the Reasons\n",
      "  - The Babadook\n"
     ]
    }
   ],
   "source": [
    "# Example id\n",
    "user_id_to_recommend = ' 0a96452695\t'\n",
    "recommend_movies(user_id_to_recommend, similar_user_buckets, top_movies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
